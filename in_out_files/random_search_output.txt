==================================================
Processing platform: NUC1
==================================================
2025-05-11_14-38-33 - Starting training of xgb.XGBRegressor...
2025-05-11_14-50-10 - xgb.XGBRegressor training finished.
2025-05-11_14-50-10 - Starting training of LinearRegression...
2025-05-11_14-50-10 - LinearRegression training finished.
2025-05-11_14-50-10 - Starting training of MLPRegressor...
2025-05-11_15-12-25 - MLPRegressor training finished.

Best model for NUC1: xgb.XGBRegressor - MAPE: 0.0061

All model results:
xgb.XGBRegressor - MAPE: 0.0061 - Parameters: xgb.XGBRegressor(colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=9, min_child_weight=6, n_estimators=151, reg_alpha=0, reg_lambda=10, subsample=0.8, missing=nan, random_state=42)
LinearRegression - MAPE: 0.0202 - Parameters: LinearRegression(fit_intercept=True)
MLPRegressor - MAPE: 0.0062 - Parameters: MLPRegressor(solver='adam', learning_rate_init=0.01, hidden_layer_sizes=(90, 100, 60), beta_2=0.99, beta_1=0.9, alpha=0.01, activation='relu', early_stopping=True, max_iter=500, random_state=42)
==================================================
Processing platform: NUC2
==================================================
2025-05-11_15-12-25 - Starting training of xgb.XGBRegressor...
2025-05-11_15-21-30 - xgb.XGBRegressor training finished.
2025-05-11_15-21-30 - Starting training of LinearRegression...
2025-05-11_15-21-30 - LinearRegression training finished.
2025-05-11_15-21-30 - Starting training of MLPRegressor...
2025-05-11_15-34-22 - MLPRegressor training finished.

Best model for NUC2: xgb.XGBRegressor - MAPE: 0.0254

All model results:
xgb.XGBRegressor - MAPE: 0.0254 - Parameters: xgb.XGBRegressor(colsample_bytree=0.7, gamma=0, learning_rate=0.3, max_depth=3, min_child_weight=6, n_estimators=144, reg_alpha=0.01, reg_lambda=0.1, subsample=0.7, missing=nan, random_state=42)
LinearRegression - MAPE: 0.0289 - Parameters: LinearRegression(fit_intercept=True)
MLPRegressor - MAPE: 0.0280 - Parameters: MLPRegressor(solver='adam', learning_rate_init=0.01, hidden_layer_sizes=(60, 30, 95), beta_2=0.999, beta_1=0.9, alpha=0.0001, activation='relu', early_stopping=True, max_iter=500, random_state=42)
==================================================
Processing platform: Server1
==================================================
2025-05-11_15-34-22 - Starting training of xgb.XGBRegressor...
2025-05-11_15-42-57 - xgb.XGBRegressor training finished.
2025-05-11_15-42-57 - Starting training of LinearRegression...
2025-05-11_15-42-57 - LinearRegression training finished.
2025-05-11_15-42-57 - Starting training of MLPRegressor...
2025-05-11_15-55-59 - MLPRegressor training finished.

Best model for Server1: xgb.XGBRegressor - MAPE: 0.0102

All model results:
xgb.XGBRegressor - MAPE: 0.0102 - Parameters: xgb.XGBRegressor(colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=192, reg_alpha=0.01, reg_lambda=0.1, subsample=0.8, missing=nan, random_state=42)
LinearRegression - MAPE: 0.0131 - Parameters: LinearRegression(fit_intercept=True)
MLPRegressor - MAPE: 0.0108 - Parameters: MLPRegressor(solver='adam', learning_rate_init=0.001, hidden_layer_sizes=(40, 70, 65), beta_2=0.99, beta_1=0.9, alpha=0.001, activation='relu', early_stopping=True, max_iter=500, random_state=42)
==================================================
Processing platform: Server2
==================================================
2025-05-11_15-55-59 - Starting training of xgb.XGBRegressor...
2025-05-11_16-04-47 - xgb.XGBRegressor training finished.
2025-05-11_16-04-47 - Starting training of LinearRegression...
2025-05-11_16-04-47 - LinearRegression training finished.
2025-05-11_16-04-47 - Starting training of MLPRegressor...
2025-05-11_16-46-31 - MLPRegressor training finished.

Best model for Server2: xgb.XGBRegressor - MAPE: 0.0297

All model results:
xgb.XGBRegressor - MAPE: 0.0297 - Parameters: xgb.XGBRegressor(colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=193, reg_alpha=0, reg_lambda=0.1, subsample=0.7, missing=nan, random_state=42)
LinearRegression - MAPE: 0.0376 - Parameters: LinearRegression(fit_intercept=True)
MLPRegressor - MAPE: 0.0643 - Parameters: MLPRegressor(solver='sgd', learning_rate_init=0.001, hidden_layer_sizes=(15, 30, 85), beta_2=0.999, beta_1=0.95, alpha=0.01, activation='relu', early_stopping=True, max_iter=500, random_state=42)
